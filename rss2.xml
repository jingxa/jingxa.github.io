<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jingxa&#39;s Blog</title>
    <link>https://jingxa.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>单影无人相依偎！</description>
    <pubDate>Thu, 25 Oct 2018 12:58:05 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>CS231A_Homework_3.3</title>
      <link>https://jingxa.github.io/2018/10/25/CS231A-Homework-3-3/</link>
      <guid>https://jingxa.github.io/2018/10/25/CS231A-Homework-3-3/</guid>
      <pubDate>Thu, 25 Oct 2018 08:08:20 GMT</pubDate>
      <description>
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;cs231A Homework-3:ps3_code-Histogram-of-Oriented-gradients&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;三、-Histogram-of-Oriented-Gradients
        
      
      </description>
      
      <content:encoded><![CDATA[<blockquote><p>cs231A Homework-3:ps3_code-Histogram-of-Oriented-gradients</p></blockquote><hr><h1 id="三、-Histogram-of-Oriented-Gradients-方向梯度直方图"><a href="#三、-Histogram-of-Oriented-Gradients-方向梯度直方图" class="headerlink" title="三、 Histogram of Oriented Gradients(方向梯度直方图)"></a>三、 Histogram of Oriented Gradients(方向梯度直方图)</h1><p>本部分内容主要实现HoG,然后进行一个简单的应用。</p><ol><li>首先，进行梯度计算；</li><li>计算直方图</li><li>计算HoG特征</li></ol><h2 id="3-1-计算梯度-compute-gradient"><a href="#3-1-计算梯度-compute-gradient" class="headerlink" title="3.1 计算梯度: compute_gradient():"></a>3.1 计算梯度: compute_gradient():</h2><p>参数：</p><ul><li>im: 灰度图片 (H, W)</li></ul><p>返回值：</p><ul><li>angles: 梯度角度 （H-2, W-2）</li><li>magnitudes: 梯度 （H-2, W-2）</li></ul><p>梯度的计算如下：</p><ul><li>给定一个像素和周围8个方向的像素，</li></ul><pre><code>P1 P2 P3P4 P5 P6P7 P8 P9arctan(dy/dx) = (P2 - p8)/(p4 - P6)  [可以使用np.arctan2 : 更稳定]，结果为[-180,180)如果想要得到[0, 180],需要简单地增加180到给负的角度梯度： sqrt((P4 - P6)^2 + (p2- P8)^ 2)</code></pre><pre><code class="python">def compute_gradient(im):    H, W = im.shape    angles = np.zeros((H-2, W-2))    magnitudes = np.zeros((H-2, W-2))       # 建立两个返回值矩阵    for i in range(1, H-1):        for j in range(1, W-1):     # 最外圈的点不计算            top = im[i-1, j]            down = im[i+1, j]            left = im[i, j-1]            right = im[i, j+1]      # 上下左右            angle = np.arctan2(top - down, left - right) * (180 / math.pi)      # 转化为度            magn = np.sqrt((top-down)**2 + (left - right)**2)            if(angle &lt; 0):      # 加180                angle += 180            angles[i-1, j-1] = angle            magnitudes[i-1, j-1] = magn    return angles, magnitudes</code></pre><h2 id="3-2-生成直方图：-generate-histogram"><a href="#3-2-生成直方图：-generate-histogram" class="headerlink" title="3.2 生成直方图： generate_histogram()"></a>3.2 生成直方图： generate_histogram()</h2><p>通过给定的角度矩阵和梯度矩阵，生成角度直方图</p><p>参数：</p><ul><li>angles: （M, N）</li><li>magnitudes:(M,N)</li><li>nbins: 直方图区间数</li></ul><p>返回值：</p><ul><li>histogram： 多维数组(nbins,),包含梯度角的分布</li></ul><p>实现：</p><ol><li>每个直方图应该被划分为0到180度，nbins决定区间数</li><li>迭代，将每个对应的梯度角度放到对应的直方图区间中，为了合理分配到两个相近的区间，使用如下公式：</li></ol><pre><code># center_angle 为 区间的中心，比如 20度的区间，第一个和第二个区间的中心为10,30    histogram[bin1] += magnitude * |angle - center_angle2 | / (180 / nbins)            histogram[bin2] += magnitude * |angle - center_angle1 | / (180 / nbins)</code></pre><p>认为第1个区间和最后一个区间相邻；</p><pre><code class="python">def generate_histogram(angles, magnitudes, nbins = 9):    histogram = np.zeros(nbins)    bin_size = 180 / nbins    center_angles = np.zeros_like(histogram)    for i in range(nbins):        center_angles[i] = (0.5 + i) * bin_size     # 计算每个区间中心    M, N = angles.shape    for m in range(M):        for n in range(N):            angle = angles[m, n]            magn = magnitudes[m, n]            abs_diff = np.abs(center_angles - angle)            # 当 angle 趋于0度            if (180 - center_angles[-1] + angle) &lt; abs_diff[-1]:        # 更新下最后区间的大小                abs_diff[-1] = 180 - center_angles[-1] + angle            # angle趋于180度            if(180 + center_angles[0] - angle) &lt; abs_diff[0]:                abs_diff[0] = 180 - angle + center_angles[0]            # 统计直方图            bin1, bin2 = np.argsort(abs_diff)[0:2]      # 取最近的两个            histogram[bin1] += magn * abs_diff[bin2] / (180.0 / nbins)            histogram[bin2] += magn * abs_diff[bin1] / (180.0 / nbins)    return histogram</code></pre><h2 id="3-3-计算HoG特征：-compute-hog-features"><a href="#3-3-计算HoG特征：-compute-hog-features" class="headerlink" title="3.3 计算HoG特征： compute_hog_features()"></a>3.3 计算HoG特征： compute_hog_features()</h2><p>参数：</p><ul><li>im： 图片矩阵</li><li>pixels_in_cell: 每个单元格的大小</li><li>cenlls_in_block:    每个block中的cell数量</li><li>nbins: histogram bins</li></ul><p>返回值：</p><ul><li>features: hog 特征（H_blocks, W_blocks, cells_in_block <em> cells_in_block </em> nbins）</li></ul><p>实现：</p><ol><li>计算每个图片的梯度和角度</li><li>定义一个cell和block</li><li>定义一个滑动窗口，大小为一个block的大小，滑动步长为block的一半，每个block中的cell存储一个直方图中的梯度，<br>每个block 特征被表示为(cells_in_block， cells_in_block, nbins),也可表示为（ cells_in_block <em> cells_in_block </em> nbins ）<br>,确保归一化</li><li>返回这些所有网格的HoG特征</li></ol><pre><code class="python">def compute_hog_features(im, pixels_in_cell, cells_in_block, nbins):    # 第一步： 获得角度和梯度    angles, magnitudes = compute_gradient(im)    # 第二步： 划分block 和cell    cell_size = pixels_in_cell    block_size = pixels_in_cell * cells_in_block    # 第三步：计算滑动窗口    H, W = angles.shape    stride = int(block_size / 2)    H_blocks = int((H - block_size) / stride) + 1    W_blocks = int((W - block_size) / stride) + 1    # 第四步： 计算每个cell的 histogram    hog_fe = np.zeros((H_blocks, W_blocks, cells_in_block * cells_in_block * nbins))    for h in range(H_blocks):        for w in range(W_blocks):            block_angles = angles[h*stride: h * stride + block_size,                           w * stride: w*stride + block_size]      # 一个block的角度            block_magn = magnitudes[h*stride: h*stride+block_size,                            w*stride: w*stride+block_size]         # 梯度            # 将一个block中的每个cell表示为一个方向直方图            block_hog_fe = np.zeros((cells_in_block, cells_in_block, nbins))            for i in range(cells_in_block):                for j in range(cells_in_block):                        cell_angles = block_angles[i*pixels_in_cell : (i+1)*pixels_in_cell,                                        j*pixels_in_cell : (j+1)*pixels_in_cell]                        cell_magns = block_magn[i*pixels_in_cell : (i+1) * pixels_in_cell,                                        j*pixels_in_cell : (j+1) * pixels_in_cell]                        cell_hist = generate_histogram(cell_angles, cell_magns, nbins)                        block_hog_fe[i, j, :] = cell_hist            # 归一化            block_hog_fe = np.reshape(block_hog_fe, -1)            block_hog_fe /= np.linalg.norm(block_hog_fe)            hog_fe[h, w, :] = block_hog_fe    return hog_fe</code></pre><h2 id="3-4-结果"><a href="#3-4-结果" class="headerlink" title="3.4 结果"></a>3.4 结果</h2><p><img src="https://github.com/jingxa/cs231a_my/raw/master/images/ps3/hog.png" alt="hog"></p><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/10/25/CS231A-Homework-3-3/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CS231A_Homework_3.2</title>
      <link>https://jingxa.github.io/2018/10/24/CS231A-Homework-3-2/</link>
      <guid>https://jingxa.github.io/2018/10/24/CS231A-Homework-3-2/</guid>
      <pubDate>Wed, 24 Oct 2018 07:36:00 GMT</pubDate>
      <description>
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;cs231A Homework-3:ps3_code-single-object-recognition&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;二、-Single-Object-Recognition-via-SIFT&quot;&gt;&lt;
        
      
      </description>
      
      <content:encoded><![CDATA[<blockquote><p>cs231A Homework-3:ps3_code-single-object-recognition</p></blockquote><hr><h1 id="二、-Single-Object-Recognition-via-SIFT"><a href="#二、-Single-Object-Recognition-via-SIFT" class="headerlink" title="二、 Single Object Recognition via SIFT"></a>二、 Single Object Recognition via SIFT</h1><p>本节主要使用SIFT实现识别和定位一个给定的对象从一堆测试图片中。</p><h2 id="2-1-关键点匹配"><a href="#2-1-关键点匹配" class="headerlink" title="2.1 关键点匹配"></a>2.1 关键点匹配</h2><p>给定一张图片的keypoint的descriptor ， 和另外多张图片的keypoint descriptors,实现一个算法能够检测关键点匹配</p><p>函数： <code>match_keypoints()</code></p><ul><li>计算一个点和另一幅图片所有点的最近两个点的欧式距离，如果（closed_point_distance / second_closed_point_distance）小于某个阈值，那么说明当前点和最近点closed_point为最佳匹配点</li></ul><p>参数：</p><ul><li>descriptors1: 第一幅图片的 descriptors ,size:(M_1, 128),每一行是一个keypoint 的 descriptor</li><li>descriptors2: 第二幅图片的 descriptors (M_2, 128)</li><li>threshold: 阈值</li></ul><p>返回值：</p><ul><li>matches: 匹配的descriptors数组,返回对应的关键点的序号对（N,2）</li></ul><pre><code class="python">def match_keypoints(descriptors1, descriptors2, threshold = 0.7):    matches_list = []    N = descriptors1.shape[0]    for i in range(N):        des1 = descriptors1[i]      # 一个点的描述符        dist = np.sqrt(np.sum((descriptors2 - des1)**2, axis=1))        # 当前点和另一幅图片所有点的欧式距离        index_sort = np.argsort(dist)           # 按照大小排序，返回序号        closed = index_sort[0]        second_closed = index_sort[1]        if(dist[closed] &lt; threshold * dist[second_closed]):            matches_list.append([i, closed])    matches = np.array(matches_list)    return matches</code></pre><h2 id="2-2-优化匹配"><a href="#2-2-优化匹配" class="headerlink" title="2.2 优化匹配"></a>2.2 优化匹配</h2><p>在上述初始匹配中，有一些错误匹配对，需要移除，这里使用RANSAC算法来计算两幅图片的单应性变换，通过变换，变换到另一幅图片的点应该和对应点的距离差值应该在一个很小的阈值内，如果超出阈值，说明不是对应点</p><p>在两幅图的单应性变换中，可以得到公式如下：</p><p><img src="https://github.com/jingxa/cs231a_my/blob/master/images/ps3/H.gif" alt="H"></p><p>因此，对应H矩阵，我们可以建立对他的9个未知量建立方程矩阵（2N*9）,其中可以得到x和y的对应等式，还有1的等式</p><p>函数：<code>refine_match()</code><br>参数：</p><ul><li>keypoints1: 第一幅图片的 关键点descriptors数组，每一行为(u,v, scale, theta)，总大小为(M_1,4)</li><li>keypoints2: 第二幅图片的特征数组</li><li>matches: 初始的配对</li><li>threshold</li><li>num_iterations: 迭代次数</li></ul><p>返回：</p><ul><li>inliers: RANSAC 拟合的对应模型的内点序列</li><li>model: RANSAC 拟合两幅图片的变换矩阵H</li></ul><pre><code class="python">def refine_match(keypoints1, keypoints2, matches, reprojection_threshold = 10,        num_iterations = 1000):    best_model = None       # 最佳模型    best_inliers = []       # 内点集合    best_count = 0          # 最佳匹配对数    sample_size = 4         # H 是 9*9矩阵，除去尺度，有八个自由度，需要4对对应点    P = np.zeros((2 * sample_size, 9))      # 建立 2N*9的矩阵，其中每个对应对建立两个等式    N = matches.shape[0]    for i in range(num_iterations):        sample_indexes = random.sample(range(0, N), sample_size)     # 随机抽取4对样本        sample = matches[sample_indexes, :]        for index, elem in enumerate(sample):       # 获得序列和数据            # 取一对对应点            p1_idx = elem[0]            p2_idx = elem[1]            # 转化为齐次坐标系            point1 = keypoints1[p1_idx, 0:2]        # u,v 坐标            point1 = np.append(point1, 1)           # (u, v, 1)            point2 = keypoints2[p2_idx, 0:2]            u = point2[0]            v = point2[1]            # 建立 P 矩阵            P[2 * index, :] = np.reshape(np.array([point1, np.zeros(3), -u * point1]), -1)            P[2 * index + 1, :] = np.reshape(np.array([np.zeros(3), point1, -v * point1]), -1)        # 求解当前的H矩阵        U, s, VT = np.linalg.svd(P)        H = VT[-1, :].reshape(3, 3)        H /= H[2, 2]        # 归一化        inliers = []        # 当前对应的 内点        count = 0        for index, match in enumerate(matches):     # 对每一对对应点进行变换评估            p1 = keypoints1[match[0], 0:2]      # u,v            p1 = np.append(p1, 1)               # (u,v,1)            p2_pred = H.dot(p1)             # p1 变换后的点            p2_pred /= p2_pred[2]           # 归一化            p2_pred = p2_pred[0:2]          # u,v            p2 = keypoints2[match[1], 0:2]            err = np.sqrt( np.sum( (p2 - p2_pred) ** 2 ) )            if err &lt; reprojection_threshold:        # 此对应点为正确                count += 1                inliers.append(index)        # 记录最佳 H        if count &gt; best_count:            best_model = H            best_inliers = inliers            best_count = count    return best_inliers, best_model</code></pre><h2 id="2-3-get-object-region"><a href="#2-3-get-object-region" class="headerlink" title="2.3 get_object_region()"></a>2.3 get_object_region()</h2><p>使用hough变换获得预测对象的边界盒子</p><p>参数：</p><ul><li>keypoints1: 同上</li><li>keypoints2</li><li>matches</li><li>obj_bbox: (xmin,ymin,xmax, ymax)</li><li>thresh: hough voting 阈值</li></ul><p>返回值：</p><ul><li>cx: 盒子中心x坐标数组</li><li>cy: 盒子中心y坐标数组</li><li>w: 盒子宽度数组</li><li>h: 盒子高度数组</li><li>orient: 盒子方向数组</li></ul><p>Hough Voting的思想就是将参数空间划分为子网格，然后统计子网格的落点计数，在此函数中：</p><ol><li>首先计算每一对对应点的边界盒子数据</li><li>然后获得盒子的最小最大的边界值，然后将整个盒子的可能空间划分为子网格</li><li>然后遍历所有的盒子数据，统计每个子网格的计数，</li><li>遍历每个子网格，如果子网格的落点大于某个阈值，那么就认为这个盒子可以做对象的边界盒子。</li></ol><pre><code class="python">def get_object_region(keypoints1, keypoints2, matches, obj_bbox, thresh = 4,        nbins = 4):    cx, cy, w, h, orient = [], [], [], [], []    # 第一步： 计算边界盒子数组    for match in matches:        p1_idx = match[0]        p2_idx = match[1]        p1 = keypoints1[p1_idx]        p2 = keypoints2[p2_idx]        u1, v1, s1, theta1 = p1[0], p1[1], p1[2], p1[3]     # 两个点的成员        u2, v2, s2, theta2 = p2[0], p2[1], p2[2], p2[3]        # 寻找对应点在img2 中的边界盒子，采用旋转平移进行计算        xmin, ymin, xmax, ymax = obj_bbox        xc1 = (xmin + xmax) / 2.0        yc1 = (ymin + ymax) / 2.0       # 中心点的坐标        w1 = (xmax - xmin) * 1.0        h1 = (ymax - ymin) * 1.0        # 使用浮点表示        O2 = theta2 - theta1        xc2 = (s2/s1) * np.cos(O2) * (xc1 - u1) - (s2/s1) * np.sin(O2) * (yc1 - v1) + u2        yc2 = (s2/s1) * np.sin(O2) * (xc1 - u1) + (s2/s1) * np.cos(O2) * (yc1 - v1) + v2        w2 = (s2/s1) * w1        h2 = (s2/s1) * h1       # 缩放        # 保存到数组中        cx.append(xc2)        cy.append(yc2)        w.append(w2)        h.append(h2)        orient.append(O2)       # 这个方向有点不理解    # 第二步： 计算盒子的子网格划分    cx_min, cx_max = min(cx), max(cx)    cy_min, cy_max = min(cy), max(cy)    w_min, w_max = min(w), max(w)    h_min, h_max = min(h), max(h)    orient_min, orient_max = min(orient), max(orient)    cx_bin_size = (cx_max - cx_min) / float(nbins)    cy_bin_size = (cy_max - cy_min) / float(nbins)    w_bin_size = (w_max - w_min) / float(nbins)    h_bin_size = (h_max - h_min) / float(nbins)    orient_bin_size = (orient_max - orient_min) / float(nbins)    # 第三步： 统计每个子网格的计数    bins = defaultdict(list)        # 由于nbins为4，那么就只计算4个参数    N = matches.shape[0]    for n in range(N):        x_center = cx[n]        y_center = cy[n]        w_center = w[n]        orient_center = orient[n]        for i in range(nbins):            for j in range(nbins):                    for k in range(nbins):                            for l in range(nbins):                                if(cx_min + i * cx_bin_size &lt;= x_center                                        and x_center &lt;= cx_min +(i+1) * cx_bin_size):       # x坐标                                            if(cy_min + j * cy_bin_size &lt;= y_center                                                and y_center &lt;= cy_min + (j+1) * cy_bin_size):                                                    if(w_min + k * w_bin_size &lt;= w_center                                                        and w_center &lt;= w_min + (k+1)*w_bin_size):                                                            if(orient_min + l*orient_bin_size &lt;= orient_center                                                                and orient_center &lt;= orient_min + (l+1) * orient_bin_size):                                                                    bins[(i, j, k, l)].append(n)    # 第四步： 统计    cx0, cy0, w0, h0, orient0 = [], [], [], [], []    for bin_idx in bins:        indices = bins[bin_idx]        votes = len(indices)        if(votes &gt;= thresh):            cx0.append(np.sum(np.array(cx)[indices]) / votes)       # 平均数            cy0.append(np.sum(np.array(cy)[indices]) / votes)            w0.append(np.sum(np.array(w)[indices]) / votes)            h0.append(np.sum(np.array(w)[indices]) / votes)            orient0.append(np.sum(np.array(orient)[indices]) / votes)    return cx0, cy0, w0, h0, orient0</code></pre><h2 id="2-4-结果"><a href="#2-4-结果" class="headerlink" title="2.4 结果"></a>2.4 结果</h2><ul><li><a href="https://github.com/jingxa/cs231a_my/tree/master/ps3_code/code_ps3" target="_blank" rel="noopener">cs231a/ps3</a></li></ul><h2 id="2-5-待解决问题"><a href="#2-5-待解决问题" class="headerlink" title="2.5 待解决问题"></a>2.5 待解决问题</h2><ol><li><p>在第二个函数中，关键点的成员包含[u, v, scale, theta],后面两个是怎么计算的？</p></li><li><p>在边界盒子的子网格统计中，使用了4个参数，但是在5个参数中，我使用h参数替换掉orient参数，结果不对，为什么呢？</p></li></ol><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/10/24/CS231A-Homework-3-2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CS231A-Homework-3.1</title>
      <link>https://jingxa.github.io/2018/10/22/CS231A-Homework-3-1/</link>
      <guid>https://jingxa.github.io/2018/10/22/CS231A-Homework-3-1/</guid>
      <pubDate>Mon, 22 Oct 2018 13:05:31 GMT</pubDate>
      <description>
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;cs231A Homework-3:ps3_code-space_carving&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;一、-Space-carving&quot;&gt;&lt;a href=&quot;#一、-Space-carving&quot; class=
        
      
      </description>
      
      <content:encoded><![CDATA[<blockquote><p>cs231A Homework-3:ps3_code-space_carving</p></blockquote><hr><h1 id="一、-Space-carving"><a href="#一、-Space-carving" class="headerlink" title="一、 Space carving"></a>一、 Space carving</h1><p>本节内容实现一个有效的Space carving 框架的部分。<br>实现过程的步骤划分如下：</p><ol><li>生成初始体素网格</li><li>实现一个视图下的carving</li><li>多视图下的carving</li><li>提高准确率</li><li>验证</li></ol><h2 id="1-生成初始体素网格：form-initial-voxels"><a href="#1-生成初始体素网格：form-initial-voxels" class="headerlink" title="1. 生成初始体素网格：form_initial_voxels()"></a>1. 生成初始体素网格：form_initial_voxels()</h2><p>函数参数</p><ul><li>xlim:x轴大小：<code>[xmin, xmax]</code></li><li>ylim: y轴大小：<code>[ymin, ymax]</code></li><li>zlim: z轴大小：<code>[zmin, zmax]</code></li><li>num_voxels: voxels的数量</li></ul><p>返回值：</p><ul><li>voxels: <code>(N,3)</code> 数组，返回N个体素的位置</li><li>voxel_size: 每个voxel的size</li></ul><blockquote><p>计算voxel_size: 即求得整个立方体体积除去数量，但是可能由于不能除尽</p><ol><li>计算每个voxel的体积，然后开三次方根，得到size</li><li>获得网格中心数组，使用<code>np.linspace</code>和<code>np.meshgrid</code><br>注意小数问题</li></ol></blockquote><ul><li><code>np.linspace(min,max,gap)</code>:在<code>[min,max]</code>区间以gap获得一个数组</li><li><a href="https://blog.csdn.net/lllxxq141592654/article/details/81532855?utm_source=blogxgwz0" target="_blank" rel="noopener">np.meshgrid</a>:获得网格矩阵</li></ul><pre><code class="python">def form_initial_voxels(xlim, ylim, zlim, num_voxels):    x_dim = xlim[1] - xlim[0]    y_dim = ylim[1] - ylim[0]    z_dim = zlim[1] - zlim[0]   # 获取三轴的长度    total_vol = x_dim * y_dim * z_dim  # 体积    one_vol = float(total_vol / num_voxels)    voxel_size = np.cbrt(one_vol)                   # 三次方根    x_voxel_num = np.round(x_dim / voxel_size)      # x轴的cube 数量,round 取整    y_voxel_num = np.round(y_dim / voxel_size)    z_voxel_num = np.round(z_dim / voxel_size)    x = np.linspace(xlim[0] + 0.5 * voxel_size,                    xlim[0] + (0.5 + x_voxel_num - 1) * voxel_size, x_voxel_num )     # 只取前 num_voxels个    y = np.linspace(ylim[0] + 0.5 * voxel_size,                    ylim[0] + (0.5 + y_voxel_num - 1) * voxel_size, y_voxel_num)     # 只取前 num_voxels个    z = np.linspace(zlim[0] + 0.5 * voxel_size,                    zlim[0] + (0.5 + z_voxel_num - 1) * voxel_size, z_voxel_num)     # 只取前 num_voxels个    XX, YY, ZZ = np.meshgrid(x, y, z)    voxels = np.r_[(XX.reshape(-1), YY.reshape(-1), ZZ.reshape(-1))].reshape(3, -1).T   # N *3    return voxels, voxel_size</code></pre><p>提示： 相关的函数：<code>np.meshgrid, np.repeat, np.tile</code></p><h2 id="2-裁剪一个视图中不属于物体的体素：carve"><a href="#2-裁剪一个视图中不属于物体的体素：carve" class="headerlink" title="2. 裁剪一个视图中不属于物体的体素：carve()"></a>2. 裁剪一个视图中不属于物体的体素：carve()</h2><p>函数参数：</p><ul><li>voxels: 体素数组</li><li>camera： 相机位置，存储数据： “silhouette” 矩阵， “image”, 和projection matrix “P”</li></ul><p>返回：</p><ul><li>voxels</li></ul><p>首先需要将3D体素投影到2D图片，移除不属于</p><pre><code class="python">def carve(voxels, camera):    N = voxels.shape[0]    homo_voxels = np.c_[voxels, np.ones((N, 1))].T  # 4 * N    voxel_index = np.arange(0, N)    P = camera.P        # 投影矩阵 3 * 4    img_voxels = P.dot(homo_voxels)   # 3 * N  , 投影到图片    img_voxels /= img_voxels[2, :]   # 归一化    img_voxels = img_voxels[0:2, :].T     # 去掉z轴 N*2    sli = camera.silhouette  # 从camera文件中了解相关信息    sli_idx = np.nonzero(sli)    xmin, xmax = np.min(sli_idx[1]), np.max(sli_idx[1])     # 列    ymin, ymax = np.min(sli_idx[0]), np.max(sli_idx[0])     # 行    voxelX = img_voxels[:, 0]    voxelY = img_voxels[:, 1]    x_filter = np.all([voxelX &gt; xmin, voxelX &lt; xmax], axis=0)       # 一个轴上的逻辑与运算    y_filter = np.all([voxelY &gt; ymin, voxelY &lt; ymax], axis=0)    filter = np.all([x_filter, y_filter], axis=0)    img_voxels = img_voxels[filter, :]      # 过滤大于轮廓矩阵的像素点    voxel_index = voxel_index[filter]     # 过滤掉序号    img_voxels = img_voxels.astype(int)     # 由于归一化，可能有小数，转为整数    sli_filter = (sli[img_voxels[:, 1], img_voxels[:, 0]] == 1)     # (x,y)是否在轮廓矩阵中    voxel_index = voxel_index[sli_filter]    return voxels[voxel_index, :]</code></pre><h2 id="3-获得更好的边界：get-voxel-bounds"><a href="#3-获得更好的边界：get-voxel-bounds" class="headerlink" title="3. 获得更好的边界：get_voxel_bounds()"></a>3. 获得更好的边界：get_voxel_bounds()</h2><p>在初始版本中的方法中，获得voxel的边界是根据相机的位置来计算的【暂时没看明白】</p><p>如果需要获得更好的边界，可以先对初始的立方体进行初始剪切一遍，然后获取得到的voxels，取得最大和最小的点，作为边界值</p><pre><code class="python">def get_voxel_bounds(cameras, estimate_better_bounds = False, num_voxels = 4000):    camera_positions = np.vstack([c.T for c in cameras])    print(camera_positions.shape)    print(&quot;0:&quot;, camera_positions[0])    xlim = [camera_positions[:,0].min(), camera_positions[:,0].max()]    ylim = [camera_positions[:,1].min(), camera_positions[:,1].max()]    zlim = [camera_positions[:,2].min(), camera_positions[:,2].max()]    # For the zlim we need to see where each camera is looking.     camera_range = 0.6 * np.sqrt(diff( xlim )**2 + diff( ylim )**2)    for c in cameras:        viewpoint = c.T - camera_range * c.get_camera_direction()        zlim[0] = min( zlim[0], viewpoint[2] )        zlim[1] = max( zlim[1], viewpoint[2] )    # Move the limits in a bit since the object must be inside the circle    xlim = xlim + diff(xlim) / 4 * np.array([1, -1])    ylim = ylim + diff(ylim) / 4 * np.array([1, -1])    if estimate_better_bounds:        voxels, voxel_size  = form_initial_voxels(xlim, ylim, zlim, num_voxels)        for c in cameras:            voxels = carve(voxels, c)        min_point = np.min(voxels, axis=0) - voxel_size        max_point = np.max(voxels, axis=0) + voxel_size        xlim[0], ylim[0], zlim[0] = min_point[0], min_point[1], min_point[2]        xlim[1], ylim[1], zlim[1] = max_point[0], max_point[1], max_point[2]    return xlim, ylim, zlim</code></pre><h2 id="4-结果"><a href="#4-结果" class="headerlink" title="4. 结果"></a>4. 结果</h2><h3 id="4-1-form-initial-voxels形成一个初始立方体"><a href="#4-1-form-initial-voxels形成一个初始立方体" class="headerlink" title="4.1 form_initial_voxels形成一个初始立方体"></a>4.1 form_initial_voxels形成一个初始立方体</h3><p><img src="https://github.com/jingxa/cs231a_my/raw/master/images/ps3/space_c_a.png" alt="iniital_voxels"></p><h3 id="4-2-carving-一个视角的裁剪"><a href="#4-2-carving-一个视角的裁剪" class="headerlink" title="4.2 carving : 一个视角的裁剪"></a>4.2 carving : 一个视角的裁剪</h3><p><img src="https://github.com/jingxa/cs231a_my/raw/master/images/ps3/space_c_b.png" alt="one_carving"></p><h3 id="4-3-没有优化边界的多视角裁剪"><a href="#4-3-没有优化边界的多视角裁剪" class="headerlink" title="4.3 没有优化边界的多视角裁剪"></a>4.3 没有优化边界的多视角裁剪</h3><p><img src="https://github.com/jingxa/cs231a_my/raw/master/images/ps3/space_c_c.png" alt="muliti_carving"></p><h3 id="4-4-优化边界的多视角裁剪"><a href="#4-4-优化边界的多视角裁剪" class="headerlink" title="4.4 优化边界的多视角裁剪"></a>4.4 优化边界的多视角裁剪</h3><p><img src="https://github.com/jingxa/cs231a_my/raw/master/images/ps3/space_c_d.png" alt="best_carving"></p><h2 id="3-参考文章"><a href="#3-参考文章" class="headerlink" title="3. 参考文章"></a>3. 参考文章</h2><ol><li><a href="https://github.com/zyxrrr/cs231a/blob/master/ps3/space_carving/main.py" target="_blank" rel="noopener">zyxrrr/cs231a</a></li><li><a href="https://github.com/mikucy/CS231A/blob/master/ps3_code/space_carving/main.py" target="_blank" rel="noopener">CS231A/ps3_code/space_carving</a></li><li><a href="https://github.com/chizhang529/cs231a/tree/master/Homework/PS3" target="_blank" rel="noopener">cs231a/Homework/PS3/</a></li></ol><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/10/22/CS231A-Homework-3-1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CS231A_说明</title>
      <link>https://jingxa.github.io/2018/10/22/CS231A-%E8%AF%B4%E6%98%8E/</link>
      <guid>https://jingxa.github.io/2018/10/22/CS231A-%E8%AF%B4%E6%98%8E/</guid>
      <pubDate>Mon, 22 Oct 2018 13:01:11 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h1&gt;&lt;h3 id=&quot;课程相关&quot;&gt;&lt;a href=&quot;#课程相关&quot; class=&quot;headerlink&quot; title=&quot;课程相关&quot;&gt;&lt;/a&gt;课程相关&lt;/h
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><h3 id="课程相关"><a href="#课程相关" class="headerlink" title="课程相关"></a>课程相关</h3><ul><li><a href="http://web.stanford.edu/class/cs231a/index.html" target="_blank" rel="noopener">CS231A: Computer Vision, From 3D Reconstruction to Recognition</a></li></ul><h3 id="本人解答过程"><a href="#本人解答过程" class="headerlink" title="本人解答过程"></a>本人解答过程</h3><ul><li>具体过程查看博客</li></ul><h3 id="参考答案"><a href="#参考答案" class="headerlink" title="参考答案"></a>参考答案</h3><ul><li><a href="https://github.com/chizhang529/cs231a" target="_blank" rel="noopener">chizhang529/cs231a</a></li><li><a href="https://github.com/mikucy/CS231A" target="_blank" rel="noopener">mikucy/CS231A</a></li><li><a href="https://github.com/zyxrrr/cs231a" target="_blank" rel="noopener">zyxrrr/cs231a</a></li></ul><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/10/22/CS231A-%E8%AF%B4%E6%98%8E/#disqus_thread</comments>
    </item>
    
    <item>
      <title>kali linux 循环登录</title>
      <link>https://jingxa.github.io/2018/09/25/kali-loop-login/</link>
      <guid>https://jingxa.github.io/2018/09/25/kali-loop-login/</guid>
      <pubDate>Tue, 25 Sep 2018 07:24:42 GMT</pubDate>
      <description>
      
        
        
          &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;想要安装一个kali linux学习，但是虚拟机测过，太卡了， 不能满足需求，因此，只能安装多系统主机。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;电脑： 
        
      
      </description>
      
      <content:encoded><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>想要安装一个kali linux学习，但是虚拟机测过，太卡了， 不能满足需求，因此，只能安装多系统主机。</p><ul><li>电脑： 电脑上已经安装了win10,ubuntu18.04；</li></ul><p>在网上找过一些安装三系统的教程，但是说的似是而非，干脆破罐子破摔，直接上！（看了几个教程都说Ultraiso好像不行，因此直接使用Win32DiskImager）</p><h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><ol><li><a href="https://mirrors.tuna.tsinghua.edu.cn/" target="_blank" rel="noopener">清华大学软件站</a> 下载kali系统</li><li><code>Win32DiskImager</code>制作U盘启动盘</li><li>先在<code>win10</code>下进行分区，压缩出一块空间不要格式化</li><li>直接重启然后选择<code>boot</code>选项，u盘启动</li><li>然后将<code>kali</code>安装到预留的磁盘</li><li>在安装过程中，会识别到win10，ubuntu的启动项，直接选择已经有的启动项</li><li>然后重启后直接进入kali的启动项，不过win10和ubuntu的启动项都在！(没有遇到什么win10和ubuntu的启动项消失的状况)</li></ol><h1 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h1><ol><li>电脑是台式机机器，安装完成后，在登录界面出现问题，账号密码正确，但是不能登录进去！</li></ol><p>解决办法：</p><ul><li><p>首先 <code>ctrl + alt + F1</code>，【其中F1~F6都可以进入命令终端模式】,<code>ctrl+alt+F7</code>:回到窗口模式</p></li><li><p>然后，需要更新系统</p></li></ul><pre><code class="bash">sudo apt-get updatesudo apt-get upgrade -f</code></pre><ul><li><code>reboot</code>即可</li></ul><h1 id="我的问题"><a href="#我的问题" class="headerlink" title="我的问题"></a>我的问题</h1><ul><li>本人的环境是wifi环境，使用了USB的wifi连接器，然后连接wifi.</li></ul><p>命令模式下的wifi连接方式：</p><ul><li><code>wpa_cli</code>:这个工具比较方便</li></ul><p>简单的使用教程：</p><pre><code class="bash">&gt; wpa_cli            # 终端中直接输入# 一般默认的wlan为wlan0,即无线网卡的名字&gt; add_network        # 这个就是创建一个新的网络连接&gt; 0                    # 默认创建的网络连接编号&gt; set_network 0 ssid &quot;mywifi&quot;    # 通过set_network给 连接0 添加 ssid ,引号中为wifi名称&gt; set_network 0 psk  &quot;12345678&quot;  # 添加密码 psk, 密码为引号中：12345678&gt; enable_network 0                 # 启动连接0# 输入 q 退出 wpa_cli&gt; q# 在终端中，打开连接~#: dhclient wlan0                 # 刚刚在wlan0上创建的连接</code></pre><ul><li>不知道是我的wifi信号不好还是怎么回事？几分钟后连接必然断开，因此，选择另一种做法！</li></ul><ol><li>如果没有<code>wpa_cli</code>，可能需要安装：</li></ol><pre><code class="bash">sudo apt-get install wireless-tools</code></pre><ol start="2"><li>配置网络：<code>修改/etc/network/interfaces文件</code></li></ol><p>在这个文件中添加需要的部分</p><pre><code class="bash">auto loiface lo inet loopbackauto eth0iface eth0 inet dhcpallow-hotplug wlan0auto wlan0iface wlan0 inet dhcp    wpa-ssid YOUR-SSID-HERE    wpa-psk YOUR-PASSWORD-HERE</code></pre><ul><li>替换上面<code>YOUR-SSID-HERE</code>： 为自己的wifi名称</li><li><code>YOUR-PASSWORD-HERE</code>: 为自己的wifi密码</li></ul><ol start="3"><li>重启连接</li></ol><pre><code class="bash">/etc/init.d/networking restart# or: service networking restart</code></pre><ul><li>如果启动失败，使用<code>journalctl -xe</code>查看系统日志，我发现我使用wpa_cli的时候启动了一个进程，杀掉相关的进程就可以了！</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><ol><li><a href="https://superuser.com/questions/987969/cant-login-in-kali-linux" target="_blank" rel="noopener">Can’t login in Kali Linux</a></li><li><a href="https://segmentfault.com/a/1190000011579147" target="_blank" rel="noopener">wpa_supplicant及wpa_cli使用方法</a></li><li><a href="http://imchao.wang/2014/01/02/make-you-raspberrypi-auto-connect-to-wifi/" target="_blank" rel="noopener">让你的树莓派连上WiFi</a></li><li><a href="https://www.jianshu.com/p/69807d3d4474" target="_blank" rel="noopener">Debian 9 下折腾 usb 无线网卡上网</a></li></ol><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/09/25/kali-loop-login/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
