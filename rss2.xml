<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jingxa&#39;s Blog</title>
    <link>https://jingxa.github.io/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>单影无人相依偎！</description>
    <pubDate>Fri, 23 Nov 2018 12:53:54 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>CS131_Homework_4</title>
      <link>https://jingxa.github.io/2018/11/22/CS131-Homework-4/</link>
      <guid>https://jingxa.github.io/2018/11/22/CS131-Homework-4/</guid>
      <pubDate>Thu, 22 Nov 2018 11:33:17 GMT</pubDate>
      <description>
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;cs131 hw4&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;主要内容&quot;&gt;&lt;a href=&quot;#主要内容&quot; class=&quot;headerlink&quot; title=&quot;主要内容&quot;&gt;&lt;/a&gt;主要内容&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;本次作业主要内
        
      
      </description>
      
      <content:encoded><![CDATA[<blockquote><p>cs131 hw4</p></blockquote><hr><h1 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h1><ul><li>本次作业主要内容是 <code>seam carving</code></li></ul><h2 id="1-Image-Reducing-using-Seam-Carving"><a href="#1-Image-Reducing-using-Seam-Carving" class="headerlink" title="1. Image Reducing using Seam Carving"></a>1. Image Reducing using Seam Carving</h2><ul><li>basic idea: 移除不重要的像素点</li><li>定义 <code>unimportant:</code> == <code>less energy pixels</code>， 一般为<code>E = {x轴方向的梯度的绝对值} + {y 轴方向的梯度的绝对值}</code></li></ul><h3 id="1-1-Energy-function"><a href="#1-1-Energy-function" class="headerlink" title="1.1 Energy function"></a>1.1 Energy function</h3><p>函数： <code>energy_function(im)</code></p><p>参数：</p><ul><li>im: 图片 (H, W, 3)</li></ul><p>返回值：</p><ul><li>每个像素点的energy (H, W)</li></ul><p>实现：<br>图像梯度一般也可以用中值差分：</p><pre><code>dx(i,j) = [I(i+1,j) - I(i-1,j)]/2;dy(i,j) = [I(i,j+1) - I(i,j-1)]/2;G(x,y) = dx(i,j) + dy(i,j);</code></pre><ul><li>这里可以使用<code>np.gradient</code></li></ul><pre><code class="python">def energy_function(image):    H, W, _ = image.shape    out = np.zeros((H, W))    gray_image = color.rgb2gray(image)    ### YOUR CODE HERE    dx, dy = np.gradient(gray_image)    out = np.abs(dx) + np.abs(dy)    ### END YOUR CODE    return out</code></pre><h3 id="1-2-compute-cost"><a href="#1-2-compute-cost" class="headerlink" title="1.2 compute cost"></a>1.2 compute cost</h3><p>这一步从图片的顶部到低端计算每个像素的<code>minimal cost</code>,即从顶端到当前像素的最小cost路径</p><p>函数：<code>compute_cost(image, energy, axis=1)</code><br>参数：</p><ul><li>image: </li><li>energy： 数组(H,W)</li><li>axis: 计算维度(width: axis=1 或者 height: axis=0)<br>返回值：</li><li>cost： 每个像素的cost，数组(H,W) </li><li>paths: lowest energy path图， 数组(H,W)，值为-1,0,1 (左上，正上，右上)判断当前像素是否在seam上</li></ul><p>实现：<br>每个像素的cost为<code>M(i,j) = E(i,j) + min(M(i-1,j-1),M(i-1,j),M(i-1,j+1))</code></p><pre><code class="python">def compute_cost(image, energy, axis=1):    energy = energy.copy()    if axis == 0:        energy = np.transpose(energy, (1, 0))    H, W = energy.shape    cost = np.zeros((H, W))    paths = np.zeros((H, W), dtype=np.int)    # Initialization    cost[0] = energy[0]    paths[0] = 0  # we don&#39;t care about the first row of paths    ### YOUR CODE HERE    for i in range(1, H):        M1 = np.r_[[1e10], cost[i-1, 0:W-1]]    # 左边添加一个无穷大        M2 = cost[i-1, :]        M3 = np.r_[cost[i-1, 1:], [1e10]]        # 右边添加一个无穷大        M = np.r_[M1, M2, M3].reshape(3, -1)        cost[i] = energy[i] + np.min(M, axis=0)     # cost        paths[i] = np.argmin(M, axis=0) - 1         # 上一层的最小值为左上角，正上方，右上角    ### END YOUR CODE    if axis == 0:        cost = np.transpose(cost, (1, 0))        paths = np.transpose(paths, (1, 0))    # Check that paths only contains -1, 0 or 1    assert np.all(np.any([paths == 1, paths == 0, paths == -1], axis=0)), \           &quot;paths contains other values than -1, 0 or 1&quot;    return cost, paths</code></pre><h2 id="2-Finding-optimal-seams"><a href="#2-Finding-optimal-seams" class="headerlink" title="2. Finding optimal seams"></a>2. Finding optimal seams</h2><p>通过上一步计算最小能量；需要移除<code>optimal seam</code>， 即最小cost的像素点连成的线</p><h3 id="2-1-Backtrack-seam"><a href="#2-1-Backtrack-seam" class="headerlink" title="2.1 Backtrack seam"></a>2.1 Backtrack seam</h3><p>函数： <code>backtrack_seam(paths, end)</code><br>参数：</p><ul><li>paths:</li><li>end: seam ends(H,end)<br>返回值：</li><li>seam: 数组(H,), </li></ul><p>实现：</p><pre><code>从下到上寻找最小：        - left (value -1)        - middle (value 0)        - right (value 1)</code></pre><p>def backtrack_seam(paths, end):<br>    H, W = paths.shape</p><pre><code># initialize with -1 to make sure that everything gets modifiedseam = - np.ones(H, dtype=np.int)# Initializationseam[H-1] = end     # 最底层的像素点位置(H-1,end)### YOUR CODE HEREfor i in range(H-2,-1,-1):    seam[i] = seam[i+1]+paths[i+1, seam[i+1]]       # 上层点的width坐标### END YOUR CODE# Check that seam only contains values in [0, W-1]assert np.all(np.all([seam &gt;= 0, seam &lt; W], axis=0)), &quot;seam contains values out of bounds&quot;return seam</code></pre><pre><code class="python"></code></pre><h3 id="2-2-Reduce"><a href="#2-2-Reduce" class="headerlink" title="2.2 Reduce"></a>2.2 Reduce</h3><p>移除上一步计算的seam</p><p>函数： <code>remove_seam(image, seam)</code></p><p>参数：</p><ul><li>seam: 每个像素点的位置为<code>image[i, seam[i]]</code></li></ul><p>返回值：</p><ul><li>out: 多维数组，(H,W,C)或者(H,W-1)</li></ul><pre><code class="python">def remove_seam(image, seam):    # Add extra dimension if 2D input    if len(image.shape) == 2:        image = np.expand_dims(image, axis=2)   # 增加一个维度    out = None    H, W, C = image.shape    ### YOUR CODE HERE    out = np.zeros((H, W - 1, C), dtype=image.dtype)        # 返回值，每一行删除一个像素    for i in range(H):        out[i, :seam[i], :]=image[i, :seam[i], :]        out[i, seam[i]:, :]=image[i, seam[i]+1:, :]    ### END YOUR CODE    out = np.squeeze(out)  # remove last dimension if C == 1    # Make sure that `out` has same type as `image`    assert out.dtype == image.dtype, \       &quot;Type changed between image (%s) and out (%s) in remove_seam&quot; % (image.dtype, out.dtype)    return out</code></pre><p>函数：<code>reduce(image, size, axis=1, efunc=energy_function, cfunc=compute_cost)</code></p><p>参数：</p><ul><li>size:根据axis移除像素知道axis的大小值为size</li></ul><p>实现：</p><ul><li>每一次移除一条最小的seam，最终移除size次</li></ul><pre><code class="python">def reduce(image, size, axis=1, efunc=energy_function, cfunc=compute_cost):    out = np.copy(image)    if axis == 0:        out = np.transpose(out, (1, 0, 2))    H = out.shape[0]    W = out.shape[1]    assert W &gt; size, &quot;Size must be smaller than %d&quot; % W    assert size &gt; 0, &quot;Size must be greater than zero&quot;    ### YOUR CODE HERE    while out.shape[1] &gt; size:        energy = efunc(out)         # 首先重新计算energy        cost, paths = cfunc(out, energy)        # 第二步计算cost map        seam = backtrack_seam(paths, np.argmin(cost[-1]))       #计算optimal seam        out = remove_seam(out, seam)                            # 移除    ### END YOUR CODE    assert out.shape[1] == size, &quot;Output doesn&#39;t have the right shape&quot;    if axis == 0:        out = np.transpose(out, (1, 0, 2))    return out</code></pre><h2 id="3-Image-Enlarging"><a href="#3-Image-Enlarging" class="headerlink" title="3. Image Enlarging"></a>3. Image Enlarging</h2><h3 id="3-1-Enlarge-naive"><a href="#3-1-Enlarge-naive" class="headerlink" title="3.1 Enlarge naive"></a>3.1 Enlarge naive</h3><p>扩大图片，可以复制seam</p><p>函数： </p><h4 id="enlarge-naive-image-size-axis-1-efunc-energy-function-cfunc-compute-cost"><a href="#enlarge-naive-image-size-axis-1-efunc-energy-function-cfunc-compute-cost" class="headerlink" title="enlarge_naive(image, size, axis=1, efunc=energy_function, cfunc=compute_cost)"></a><code>enlarge_naive(image, size, axis=1, efunc=energy_function, cfunc=compute_cost)</code></h4><p>增大图片某axis到size大小<br>Use functions:</p><pre><code>- efunc- cfunc- backtrack_seam- duplicate_seam</code></pre><p>返回值： out数组(size, W, c)如果axis=0, 或 (H, size, c) 如果axis=1</p><h4 id="enlarge-image-size-axis-1-efunc-energy-function-cfunc-compute-cost"><a href="#enlarge-image-size-axis-1-efunc-energy-function-cfunc-compute-cost" class="headerlink" title="enlarge(image, size, axis=1, efunc=energy_function, cfunc=compute_cost)"></a><code>enlarge(image, size, axis=1, efunc=energy_function, cfunc=compute_cost)</code></h4><p>寻找多条lowest energy seam<br>Use functions:</p><pre><code>- find_seams- duplicate_seam</code></pre><p>返回值： out数组(size, W, c)如果axis=0, 或 (H, size, c) 如果axis=1    </p><pre><code class="python">def enlarge_naive(image, size, axis=1, efunc=energy_function, cfunc=compute_cost):    out = np.copy(image)    if axis == 0:        out = np.transpose(out, (1, 0, 2))    H = out.shape[0]    W = out.shape[1]    assert size &gt; W, &quot;size must be greather than %d&quot; % W    ### YOUR CODE HERE    while out.shape[1] &lt; size:        energy = efunc(out)         # 首先重新计算energy        cost, paths = cfunc(out, energy)        # 第二步计算cost map        seam = backtrack_seam(paths, np.argmin(cost[-1]))       #计算optimal seam        out = duplicate_seam(out, seam)                            # 复制    ### END YOUR CODE    if axis == 0:        out = np.transpose(out, (1, 0, 2))    return outdef enlarge(image, size, axis=1, efunc=energy_function, cfunc=compute_cost):    out = np.copy(image)    # Transpose for height resizing    if axis == 0:        out = np.transpose(out, (1, 0, 2))    H, W, C = out.shape    assert size &gt; W, &quot;size must be greather than %d&quot; % W    assert size &lt;= 2 * W, &quot;size must be smaller than %d&quot; % (2 * W)    ### YOUR CODE HERE    seams = find_seams(out, size - W)       # 寻找size - W 条 seam    seams = np.expand_dims(seams, axis=2)   # (H,W)    for i in range(size - W):        out = duplicate_seam(out, np.where(seams == i+1)[1])        # 复制当前 seam        seams = duplicate_seam(seams, np.where(seams == i+1)[1])    # seam也复制    ### END YOUR CODE    if axis == 0:        out = np.transpose(out, (1, 0, 2))    return out    </code></pre><h2 id="4-Faster-reduce"><a href="#4-Faster-reduce" class="headerlink" title="4. Faster reduce"></a>4. Faster reduce</h2><ul><li>【暂时没有搞明白 ， 使用别人的代码】</li></ul><p>函数： <code>reduce_fast(image, size, axis=1, efunc=energy_function, cfunc=compute_cost)</code></p><h2 id="5-Forward-Energy"><a href="#5-Forward-Energy" class="headerlink" title="5. Forward Energy"></a>5. Forward Energy</h2><p>函数：<code>compute_forward_cost(image, energy)</code></p><p>实现：</p><pre><code>M1: M(i-1,j-1)M2: M(i-1,j)M3: M(i-1,j+1)CL(i,j): |I(i,j+1) - I(i,j-1)| + |I(i-1,j) - I(i,j-1)|CL(i,j): |I(i,j+1) - I(i,j-1)| + |I(i-1,j) - I(i,j+1)|CV(i,j): |I(i,j+1) - I(i,j-1)|M(i,j) = min{{M1+CL(i,j)}, {M2 + Cv(i,j)}, {M3+CR(i,j)}}</code></pre><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/11/22/CS131-Homework-4/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CS231A_Homework_4.2</title>
      <link>https://jingxa.github.io/2018/11/06/CS231A-Homework-4-2/</link>
      <guid>https://jingxa.github.io/2018/11/06/CS231A-Homework-4-2/</guid>
      <pubDate>Tue, 06 Nov 2018 12:19:14 GMT</pubDate>
      <description>
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;cs231A Homework-4: Image Segmentation&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;2-Image-Segmentation&quot;&gt;&lt;a href=&quot;#2-Image-Segmentation&quot; c
        
      
      </description>
      
      <content:encoded><![CDATA[<blockquote><p>cs231A Homework-4: Image Segmentation</p></blockquote><hr><h1 id="2-Image-Segmentation"><a href="#2-Image-Segmentation" class="headerlink" title="2. Image Segmentation"></a>2. Image Segmentation</h1><p>本节主要实现两个经典的分割方法</p><ul><li>k-means</li><li>meanshift</li></ul><h2 id="2-1-k-means"><a href="#2-1-k-means" class="headerlink" title="2.1 k-means"></a>2.1 k-means</h2><p>函数：<code>kmeans_segmentation(im, features, num_clusters)</code><br>参数：</p><ul><li>im: 图片（H,W,3）</li><li>features: 每个像素点的特征（#pixels, M), #pixels为(H,W)，特征为[row,col, R,G,B]</li><li>num_clusters: 聚类数量</li></ul><p>返回值：</p><ul><li>pixel_cluster: (H,W)矩阵，每个像素点属于的cluster</li></ul><p>实现：</p><ol><li>随机选择num_clusters个中心</li><li>重复下面步骤直到收敛：<ul><li>将每个像素点归到最近的像素中心点</li><li>计算每个集合的特征的均值中心</li><li>直到每个集合的中心不再发生变化</li></ul></li></ol><pre><code class="python">def kmeans_segmentation(im, features, num_clusters):    H, W = im.shape[0], im.shape[1]    N = features.shape[0]    # 第一步： 随机选择num_clusters个种子    center_idx = np.random.randint(N, size=num_clusters)    centriods = features[center_idx]    matrixes = np.zeros((H, W))    # 第二步： 迭代器划分    while True:        # 每个像素到cneter的距离        dist = np.zeros((N, num_clusters))        for i in range(num_clusters):            dist[:, i] = np.linalg.norm(features - centriods[i, :], axis=1)     # 距离        # 寻找最近中心        nearest = np.argmin(dist, axis=1)       # (N,1)        # 更新        prev_centriods = centriods        for i in range(num_clusters):            pixels_idx = np.where(nearest == i)      # 和 第 i 个中心邻近的像素集合            cluster = features[pixels_idx]            # (M,5)            centriods[i, :] = np.mean(cluster, axis=0)      # 重新计算平均值        # 收敛        if np.array_equal(prev_centriods, centriods):            break    pixels_clusters = np.reshape(nearest, (H, W))    return pixels_clusters</code></pre><h2 id="2-2-meanshift"><a href="#2-2-meanshift" class="headerlink" title="2.2 meanshift"></a>2.2 meanshift</h2><p>函数： <code>meanshift_segmentation(im, features, bandwidth)</code></p><p>参数： </p><ul><li>im: 图片</li><li>features: 如上</li><li>bandwidth: 均值计算半径</li></ul><p>返回值：</p><ul><li>pixel_cluster: H*W 矩阵</li></ul><p>实现：</p><ol><li>随机选择一个未遍历过的像素</li><li>重新计算均值直到变化不超过1%，将 bandwidth 内的像素点归到当前cluster</li><li>如果当前cluster漂移，和另一个clouster中心近于半个 bandwidth, 将两个归于一个cluster</li><li>否则，创建一个新的cluster</li></ol><pre><code class="python">def meanshift_segmentation(im, features, bandwidth):    H, W = im.shape[0], im.shape[1]    N, M = features.shape       # 数量， 特征维度    mask = np.ones(N)    clusters = []    while np.sum(mask) &gt; 0 :    # 当前还有像素未被遍历        loc = np.argwhere(mask &gt; 0)        idx = loc[int(np.random.choice(loc.shape[0], 1)[0])][0]     # 随扈挑选一个像素        mask[idx] = 0   # 标记        current_mean = features[idx]        prev_mean = current_mean        while True:            dist = np.linalg.norm(features - prev_mean, axis=1)            incircle = dist &lt; bandwidth # 距离小于半径的点            mask[incircle] = 0            current_mean = np.mean(features[incircle], axis=0)  # 新的中心            # 稳定，收敛            if np.linalg.norm(current_mean - prev_mean) &lt; 0.01 * bandwidth:                break            prev_mean = current_mean        isValid = True        for cluster in clusters:            if np.linalg.norm(cluster - current_mean) &lt; 0.5 * bandwidth:   # 两个划分为一个cluster                isValid = False        if isValid:     # 添加一个新cluster            clusters.append(current_mean)    pixels_clusters = np.zeros((H, W))    clusters = np.array(clusters)    for i in range(N):     # 计算每个像素点的最近中心        idx = np.argmin(np.linalg.norm(features[i, :] - clusters, axis=1))        h = int(i/W)        w = i % W        pixels_clusters[h, w] = idx    return  pixels_clusters.astype(int)</code></pre><h2 id="2-3-结果"><a href="#2-3-结果" class="headerlink" title="2.3 结果"></a>2.3 结果</h2><h3 id="k-means"><a href="#k-means" class="headerlink" title="k-means"></a>k-means</h3><p><img src="https://raw.githubusercontent.com/jingxa/cs231a_my/master/images/ps4/ps4_b_1.png" alt="ps4_b_1"><br><img src="https://raw.githubusercontent.com/jingxa/cs231a_my/master/images/ps4/ps4_b_2.png" alt="ps4_b_2"><br><img src="https://raw.githubusercontent.com/jingxa/cs231a_my/master/images/ps4/ps4_b_3.png" alt="ps4_b_3"></p><h3 id="meanshift"><a href="#meanshift" class="headerlink" title="meanshift"></a>meanshift</h3><p><img src="https://raw.githubusercontent.com/jingxa/cs231a_my/master/images/ps4/ps4_c_1.png" alt="ps4_c_1"><br><img src="https://raw.githubusercontent.com/jingxa/cs231a_my/master/images/ps4/ps4_c_2.png" alt="ps4_c_2"><br><img src="https://raw.githubusercontent.com/jingxa/cs231a_my/master/images/ps4/ps4_c_3.png" alt="ps4_c_3"></p><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/11/06/CS231A-Homework-4-2/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CS231A_Homework_4.1</title>
      <link>https://jingxa.github.io/2018/11/06/CS231A-Homework-4-1/</link>
      <guid>https://jingxa.github.io/2018/11/06/CS231A-Homework-4-1/</guid>
      <pubDate>Tue, 06 Nov 2018 12:19:00 GMT</pubDate>
      <description>
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;cs231A Homework-4: Face Detection&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;1-Face-Detection-with-HoG&quot;&gt;&lt;a href=&quot;#1-Face-Detection-with-
        
      
      </description>
      
      <content:encoded><![CDATA[<blockquote><p>cs231A Homework-4: Face Detection</p></blockquote><hr><h1 id="1-Face-Detection-with-HoG"><a href="#1-Face-Detection-with-HoG" class="headerlink" title="1. Face Detection with HoG"></a>1. Face Detection with HoG</h1><p>本节作业主要利用HoG来计算特征，并且作为目标检测的一部分。</p><h2 id="1-1-运行SVM训练输出边界盒子"><a href="#1-1-运行SVM训练输出边界盒子" class="headerlink" title="1.1 运行SVM训练输出边界盒子"></a>1.1 运行SVM训练输出边界盒子</h2><p>函数：<code>run_detector(im, clf, window_size, cell_size, block_size, nbins, thresh=1)</code><br>参数：</p><ul><li>im: 图片</li><li>clf: svm对象，使用<code>decision_function()</code>确定对象是否为face</li><li>window_size: 滑动窗口的size数组</li><li>cell_size: (cell_size, cell_size)包含pixels</li><li>block_size: （block_size, block_size)包含的cells</li><li>nbins： 直方图的bins</li></ul><p>返回值：</p><ul><li>bboxes: (D * 4) 的边界盒子数组【xmin, ymin,width, height】</li><li>scores: 每个边界盒子的SVM scores</li></ul><p>实现：</p><ol><li>使用<code>compute_hog_features()</code>计算HoG特征</li><li>对滑动窗口计算score,每次滑动的步长为n pixels，步长stride = (block_size * cell_size / 2)</li><li>SVM得到的score大于1，就认为窗口为边界盒子</li></ol><pre><code class="python">def run_detector(im, clf, window_size, cell_size, block_size, nbins, thresh=1):    H, W = im.shape    win_H, win_W = window_size    stride = int(block_size * cell_size / 2)    # 返回值    bboxes = []    scores = []    # 计算每个窗口是否为face    for i in range(0, W - win_W, stride):        for j in range(0, H - win_H, stride):            bbox = [i, j, win_W, win_H]     # 窗口 [xmin ymin width height]            im_bbox = im[j:j+win_H, i: i+win_W]            feature_im = compute_hog_features(im_bbox, cell_size, block_size, nbins)        # HoG            score_im = clf.decision_function(feature_im.flatten().reshape(1,-1))        # 先将HoG特征变为vector,然后进行判断是否为face特征            if score_im &gt; thresh:                scores.append(score_im)                bboxes.append(bbox)    # 变换为numpy类型    bboxes = np.array(bboxes)    scores = np.array(scores)    return bboxes, scores</code></pre><h2 id="1-2-非最大化约束"><a href="#1-2-非最大化约束" class="headerlink" title="1.2 非最大化约束"></a>1.2 非最大化约束</h2><p>在上一步执行的face窗口检测中，可能存在一个face侦测多个窗口的情况，对于每个窗口，都有一个score，因此对于同一个face的窗口，比较score,留下最高的窗口，移除剩下的窗口。</p><p>函数: <code>non_max_suppression(bboxes, confidences)</code></p><p>参数： </p><ul><li><code>bboxes:</code> 窗口 (N, 4)</li><li>confidences: 每个窗口的SVM confidence信度 （N,1），即score</li></ul><p>返回值：</p><ul><li>nmss_bboxes: 非重叠的窗口，即移除弱特征的窗口</li></ul><p>实现：</p><ol><li>首先sort 窗口confidence</li><li>然后移除重叠的窗口</li></ol><pre><code class="python">def non_max_suppression(bboxes, confidences):    nms_bboxs = []   # 返回窗口    # 对confidences 排序    con_idx = np.argsort(-confidences.flatten())          # 从大到小排列    N = bboxes.shape[0]    for i in range(N):        bbox = bboxes[con_idx[i], :]        # 一个窗口,[xmin, ymin, width, height]        if i == 0:      # 第一个窗口，加入结果序列            nms_bboxs.append(bbox)        else:           # 查看当前窗口是否和已有窗口重叠            # 计算窗口中心            cx = (2 * bbox[0] + bbox[2]) / 2            cy = (2 * bbox[1] + bbox[3]) / 2            isOverlap = False            for j in range(len(nms_bboxs)):                xmin, ymin, w, h = nms_bboxs[j][0], nms_bboxs[j][1],\                                   nms_bboxs[j][2], nms_bboxs[j][3]                xmax, ymax = (xmin + w), (ymin + h)                if xmin &lt;= cx &lt;= xmax and ymin &lt;= cy &lt;= ymax:     # 两个窗口重叠                    isOverlap = True                    break            if not isOverlap:       # 没有重叠                nms_bboxs.append(bbox)    nms_bboxs = np.array(nms_bboxs)    return nms_bboxs</code></pre><h2 id="1-3-结果"><a href="#1-3-结果" class="headerlink" title="1.3 结果"></a>1.3 结果</h2><p><img src="https://raw.githubusercontent.com/jingxa/cs231a_my/master/images/ps4/ps4_a_1.png" alt="ps4_a_1"><br><img src="https://raw.githubusercontent.com/jingxa/cs231a_my/master/images/ps4/ps4_a_2.png" alt="ps4_a_2"></p><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/11/06/CS231A-Homework-4-1/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CS131-Homework-3</title>
      <link>https://jingxa.github.io/2018/10/29/CS131-Homework-3/</link>
      <guid>https://jingxa.github.io/2018/10/29/CS131-Homework-3/</guid>
      <pubDate>Mon, 29 Oct 2018 02:12:08 GMT</pubDate>
      <description>
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;cs131 hw3&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;内容&quot;&gt;&lt;a href=&quot;#内容&quot; class=&quot;headerlink&quot; title=&quot;内容&quot;&gt;&lt;/a&gt;内容&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Harries corner 
        
      
      </description>
      
      <content:encoded><![CDATA[<blockquote><p>cs131 hw3</p></blockquote><hr><h1 id="内容"><a href="#内容" class="headerlink" title="内容"></a>内容</h1><ul><li>Harries corner detector</li><li>RANSAC</li><li>HoG descriptor</li></ul><h1 id="相关：-Panaorama-Stitching-全景拼接"><a href="#相关：-Panaorama-Stitching-全景拼接" class="headerlink" title="相关： Panaorama Stitching(全景拼接)"></a>相关： Panaorama Stitching(全景拼接)</h1><p>全景图片的拼接过程一般如下：</p><ol><li>使用<code>Harries detector</code>寻找关键点</li><li>建立每个关键点的descriptor, 比较两幅图片的descriptor，寻找keypoints对</li><li>在keypoints对上，使用 <code>least-squares method</code>求解仿设变换矩阵</li><li>使用RANSAC优化矩阵，然后对多幅图片进行变换，得到全景</li></ol><p>额外的任务：</p><ul><li>实现HoG descriptor</li></ul><h2 id="1-Harris-Corner-Detector"><a href="#1-Harris-Corner-Detector" class="headerlink" title="1. Harris Corner Detector"></a>1. Harris Corner Detector</h2><p>harris 的基本算法分为如下几步：</p><pre><code class="python">def harris_corners(img, window_size=3, k=0.04):    H, W = img.shape    window = np.ones((window_size, window_size))    response = np.zeros((H, W))    #第一步： 偏导数    dx = filters.sobel_v(img)    dy = filters.sobel_h(img)    # 第二步： 偏导数乘积    dxx = dx * dx    dyy = dy * dy    dxy = dx * dy    # 第三步： 形成矩阵    mxx = convolve(dxx, window)    mxy = convolve(dxy, window)    myy = convolve(dyy, window)      #加权计算    # 第四步： 计算response    for i in range(H):        for j in range(W):            M = np.array([[mxx[i, j], mxy[i, j]], [mxy[i, j], myy[i, j]]])            response[i, j] = np.linalg.det(M) - k * np.trace(M) ** 2    return response</code></pre><h2 id="2-Describing-and-Matching-Keypoints"><a href="#2-Describing-and-Matching-Keypoints" class="headerlink" title="2. Describing and Matching Keypoints"></a>2. Describing and Matching Keypoints</h2><h3 id="2-1-Descriptors-创建"><a href="#2-1-Descriptors-创建" class="headerlink" title="2.1 Descriptors 创建"></a>2.1 Descriptors 创建</h3><p>函数： <code>simple_descriptor()</code><br>参数： </p><ul><li>patch: 灰度图片的一个patch，大小（H,W）</li></ul><p>返回值：</p><ul><li>features： 1D的数组(H * W)</li></ul><p>实现：</p><ul><li>将H * W 的patch排列为1D，然后归一化,采用高斯核（x - u）/delta </li></ul><pre><code class="python">def simple_descriptor(patch):    feature = []    patch = patch.reshape(-1)    mean = np.mean(patch)       # 均值    delta = np.std(patch)       # 标准差    if delta &gt; 0.0:        patch = (patch - mean) / delta    else:        patch = patch - mean    feature = list(patch)    return feature</code></pre><h2 id="2-2-descriptors匹配"><a href="#2-2-descriptors匹配" class="headerlink" title="2.2 descriptors匹配"></a>2.2 descriptors匹配</h2><ul><li>通过计算两个descriptors的欧式距离来比较</li><li>点A：最近点B,第二近点C</li><li>如果（dist(A-B)/ dist(A-C)） 小于某个阈值，说明A与B为最佳配对</li></ul><p>函数：<code>match_descriptors(desc1, desc2, threshold=0.5)</code><br>参数：</p><ul><li>desc1,desc2: 两个描述符数组</li><li>thresh： 阈值</li></ul><p>返回值：</p><ul><li>matches:配对点</li></ul><pre><code class="python">def match_descriptors(desc1, desc2, threshold=0.5):    matches = []    N = desc1.shape[0]    dists = cdist(desc1, desc2)     # 每个向量的欧式距离 N * N    idx = np.argsort(dists, axis=1)     # 从小到大对dist排序，返回序号， N * N    for i in range(N):        closed_dist = dists[i, idx[i, 0]]        second_dist = dists[i, idx[i, 1]]        if(closed_dist &lt; threshold * second_dist):      # 比较            matches.append([i, idx[i, 0]])    matches = np.array(matches)    return matches</code></pre><h2 id="3-Transformation-Estimation"><a href="#3-Transformation-Estimation" class="headerlink" title="3. Transformation Estimation"></a>3. Transformation Estimation</h2><p>-通过匹配点来估计两个图片的仿射变换，使用最小二乘法来计算</p><p>函数： <code>fit_affine_matrix(p1, p2)</code></p><p>参数： </p><ul><li>p1, p2: 两组对应点</li></ul><p>返回值：</p><ul><li>H： 仿射变换</li></ul><pre><code class="python">def fit_affine_matrix(p1, p2):    assert (p1.shape[0] == p2.shape[0]),\        &#39;Different number of points in p1 and p2&#39;    p1 = pad(p1)    p2 = pad(p2)        # 齐次矩阵    H = np.linalg.lstsq(p2, p1)[0]    # Sometimes numerical issues cause least-squares to produce the last    # column which is not exactly [0, 0, 1]    H[:,2] = np.array([0, 0, 1])    return H</code></pre><h2 id="4-RANSAC-优化匹配"><a href="#4-RANSAC-优化匹配" class="headerlink" title="4. RANSAC 优化匹配"></a>4. RANSAC 优化匹配</h2><p>一般步骤为：</p><ol><li>选择随机的匹配对</li><li>计算仿射变换矩阵</li><li>寻找RANSAC拟合的inliers</li><li>重复直到找到包含inliers最多的模型</li><li>重新计算最小二乘误差 在内点</li></ol><p>函数： <code>ransac(keypoints1, keypoints2, matches, n_iters=200, threshold=20)</code></p><p>参数：</p><ul><li>keypoints1, keypoints2: 关键点</li><li>matches： 对应点序号</li><li>n_iters: 迭代次数</li><li>thresh:  阈值</li></ul><p>返回值：</p><ul><li>H : 仿射变换矩阵</li></ul><p>实现：</p><ul><li>RANSAC寻找的就是使得配对点数尽可能多的H。</li><li>首先，随机挑选对应对，使用最小二乘求解一个变换h,计算通过当前h，能够得到的最大对应点的数量</li><li>然后，迭代n_iters次，选择最大对应点数量的变换矩阵矩阵H</li><li>另一种实现方式，可以查看[cs231A_Homework_3.2]</li></ul><pre><code class="python">def ransac(keypoints1, keypoints2, matches, n_iters=200, threshold=20):    # Copy matches array, to avoid overwriting it    orig_matches = matches.copy()    matches = matches.copy()    N = matches.shape[0]    print(N)    n_samples = int(N * 0.2)                            # 随机取样    matched1 = pad(keypoints1[matches[:, 0]])            #第一列的序号 齐次矩阵    matched2 = pad(keypoints2[matches[:, 1]])            # 第二列的序号    max_inliers = np.zeros(N)    n_inliers = 0    # RANSAC iteration start    for i in range(n_iters):        temp_max = np.zeros(N, dtype=np.int32)      # 临时变量        temp_n = 0        idx = np.random.choice(N, n_samples, replace=False)     # 随机抽取 n_samples        p1 = matched1[idx, :]        p2 = matched2[idx, :]        H = np.linalg.lstsq(p2, p1)[0]              # 临时变换 H        H[:, 2] = np.array([0, 0, 1])        temp_max = np.linalg.norm(matched2.dot(H) - matched1, axis=1) ** 2 &lt; threshold      # 计算当前对应点的数量        temp_n = np.sum(temp_max)        if temp_n &gt; n_inliers:          # 保存最大数量            max_inliers = temp_max.copy()            n_inliers = temp_n    H = np.linalg.lstsq(matched2[max_inliers], matched1[max_inliers])[0]    H[:, 2] = np.array([0, 0, 1])    return H, matches[max_inliers]</code></pre><h2 id="5-HoG"><a href="#5-HoG" class="headerlink" title="5. HoG"></a>5. HoG</h2><p>HoG的计算步骤一般如下：</p><ol><li>计算图片的x,y方向上的偏导数，使用<code>skimage.filters</code></li><li>将图片划分多个block,每个block划分为cells,计算每个cell的梯度直方图</li><li>flatten 每个block为特征向量</li><li>归一化</li></ol><p>函数：<code>hog_descriptor(patch, pixels_per_cell=(8,8))</code><br>参数：</p><ul><li>patch : 图片(H,W)</li><li>pixels_per_cell: 每个cell的size(M,N)</li></ul><p>返回值：</p><ul><li>block : 一个block的特征向量（（H<em>W</em>n_bins） / (M*N)）<br>实现：</li><li>将patch划分为多个cells,计算每个cells的梯度，然后计算梯度直方图</li><li>最后归一化</li></ul><pre><code class="python">def hog_descriptor(patch, pixels_per_cell=(8,8)):    assert (patch.shape[0] % pixels_per_cell[0] == 0),\                &#39;Heights of patch and cell do not match&#39;    assert (patch.shape[1] % pixels_per_cell[1] == 0),\                &#39;Widths of patch and cell do not match&#39;    n_bins = 9    degrees_per_bin = 180 // n_bins             # 8 个方向，每个方向 20 度    # sobel求解梯度    Gx = filters.sobel_v(patch)    Gy = filters.sobel_h(patch)    # 梯度值和方向    G = np.sqrt(Gx**2 + Gy**2)    theta = (np.arctan2(Gy, Gx) * 180 / np.pi) % 180    # Group entries of G and theta into cells of shape pixels_per_cell, (M, N)    #   G_cells.shape = theta_cells.shape = (H//M, W//N)    #   G_cells[0, 0].shape = theta_cells[0, 0].shape = (M, N)    G_cells = view_as_blocks(G, block_shape=pixels_per_cell)            # 划分为block    theta_cells = view_as_blocks(theta, block_shape=pixels_per_cell)    rows = G_cells.shape[0]    cols = G_cells.shape[1]    # For each cell, keep track of gradient histrogram of size n_bins    cells = np.zeros((rows, cols, n_bins))    # Compute histogram per cell    for i in range(rows):        for j in range(cols):            for m in range(pixels_per_cell[0]):                for n in range(pixels_per_cell[1]):                    idx = int(theta_cells[i, j, m, n] // degrees_per_bin)       # 计算当前像素点 位于n_bins 直方图的那个区间                    if idx == 9:    # 180 度                        idx = 8                    cells[i, j, idx] += G_cells[i, j, m, n]             # 统计    cells = (cells - np.mean(cells)) / np.std(cells)        # 归一化    block = cells.reshape(-1)    return block</code></pre><h2 id="6-图片融合"><a href="#6-图片融合" class="headerlink" title="6. 图片融合"></a>6. 图片融合</h2><p>当两张图片融合的时候，可以看到明显的线条，使用一种叫做<strong>linear blending</strong>的方法平滑消除问题。</p><p>基本步骤如下：</p><ol><li>定义 left 和 right margins</li><li>定义一个 weight matrix 对于图片1：<ul><li>左边的权重 等于1</li><li>从left margin 到 right margin， 权重 递减为 1  to 0</li></ul></li><li>定一个 图片2 的 weight matrix<ul><li>在 right margin 的右边，定义 weight = 1</li><li>从right margin to left margin, 权重递减 为 0 to 1</li></ul></li><li>将 weight matrix 应用对应的图片上</li><li>合并图片</li></ol><pre><code class="python">def linear_blend(img1_warped, img2_warped):    &quot;&quot;&quot;    Linearly blend img1_warped and img2_warped by following the steps:    1. Define left and right margins (already done for you)    2. Define a weight matrices for img1_warped and img2_warped        np.linspace and np.tile functions will be useful    3. Apply the weight matrices to their corresponding images    4. Combine the images    Args:        img1_warped: Refernce image warped into output space        img2_warped: Transformed image warped into output space    Returns:        merged: Merged image in output space    &quot;&quot;&quot;    out_H, out_W = img1_warped.shape # Height and width of output space    img1_mask = (img1_warped != 0)  # Mask == 1 inside the image    img2_mask = (img2_warped != 0) # Mask == 1 inside the image    # Find column of middle row where warped image 1 ends    # This is where to end weight mask for warped image 1    # np.fliplr 左右翻转； np.argmax:最大值的下标    right_margin = out_W - np.argmax(np.fliplr(img1_mask)[out_H//2, :].reshape(1, out_W), 1)[0] # 最大值列    # Find column of middle row where warped image 2 starts    # This is where to start weight mask for warped image 2    left_margin = np.argmax(img2_mask[out_H//2, :].reshape(1, out_W), 1)[0]    left_matrix = np.array(img1_mask,  dtype=np.float64)        # 非常重要。转换为浮点类型    right_matrix = np.array(img2_mask, dtype=np.float64)    # 渐进变换区域    left_matrix[:, left_margin: right_margin] = np.tile(np.linspace(1, 0, right_margin - left_margin), (out_H, 1))    right_matrix[:, left_margin: right_margin] = np.tile(np.linspace(0, 1, right_margin - left_margin), (out_H, 1))    img1 = left_matrix * img1_warped    img2 = right_matrix * img2_warped    merged = img1 + img2    return merged</code></pre><p>上述方法存在一些问题，因为在两幅图片的margin判断的时候，可能没有取到边界的地方，导致结果图片中存在错误。</p><p>可以使用下面的一种方法，先计算</p><pre><code>merged = img1_warped + img2_warped img1_mask = img1_mask * 1.0img2_mask = img2_mask * 1.0merged = img1_warped + img2_warpedoverlap = (img1_mask * 1.0 + img2_mask)### YOUR CODE HERE#找到填充图像2的左边界，也就是列像素不全为0的位置for col in range(img2_warped.shape[1]):    if not np.all(img2_mask[:,col]==False):        breakleft_region = col right_region = img1.shape[1]width_region = right_region - left_region + 1for col in range(left_region, right_region +1):    for row in range(img2_warped.shape[0]):        alpha = 1 - (col - left_region)/width_region        if img1_mask[row, col] and img2_mask[row, col]:            merged[row, col] = alpha * img1_warped[row, col] + (1 - alpha) * img2_warped[row, col]output = merged        ### END YOUR CODE</code></pre><h2 id="7-全景融合"><a href="#7-全景融合" class="headerlink" title="7. 全景融合"></a>7. 全景融合</h2><ul><li>略</li></ul><h1 id="2-结果"><a href="#2-结果" class="headerlink" title="2. 结果"></a>2. 结果</h1><ul><li><a href="https://github.com/jingxa/CS131_release/blob/master/hw3_release/hw3.ipynb" target="_blank" rel="noopener">my_cs131_hw3</a></li></ul><h1 id="3-参考资料"><a href="#3-参考资料" class="headerlink" title="3. 参考资料"></a>3. 参考资料</h1><ul><li><a href="https://github.com/Jack-An/CS131/blob/master/hw3_release/hw3.ipynb" target="_blank" rel="noopener">Jack-An/CS131</a></li><li><a href="https://github.com/nizihabi/Stanford_CS131_HW/blob/master/hw3_release/hw3.ipynb" target="_blank" rel="noopener">nizihabi/Stanford_CS131_HW</a></li><li><a href="https://github.com/mikucy/CS131/blob/master/hw3_release/hw3.ipynb" target="_blank" rel="noopener">mikucy/CS131</a></li><li><a href="https://github.com/wwdguu/CS131_homework/blob/master/hw3_release/hw3.ipynb" target="_blank" rel="noopener">wwdguu/CS131_homework</a></li></ul><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/10/29/CS131-Homework-3/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CS231A_Homework_3.3</title>
      <link>https://jingxa.github.io/2018/10/25/CS231A-Homework-3-3/</link>
      <guid>https://jingxa.github.io/2018/10/25/CS231A-Homework-3-3/</guid>
      <pubDate>Thu, 25 Oct 2018 08:08:20 GMT</pubDate>
      <description>
      
        
        
          &lt;blockquote&gt;
&lt;p&gt;cs231A Homework-3:ps3_code-Histogram-of-Oriented-gradients&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;h1 id=&quot;三、-Histogram-of-Oriented-Gradients
        
      
      </description>
      
      <content:encoded><![CDATA[<blockquote><p>cs231A Homework-3:ps3_code-Histogram-of-Oriented-gradients</p></blockquote><hr><h1 id="三、-Histogram-of-Oriented-Gradients-方向梯度直方图"><a href="#三、-Histogram-of-Oriented-Gradients-方向梯度直方图" class="headerlink" title="三、 Histogram of Oriented Gradients(方向梯度直方图)"></a>三、 Histogram of Oriented Gradients(方向梯度直方图)</h1><p>本部分内容主要实现HoG,然后进行一个简单的应用。</p><ol><li>首先，进行梯度计算；</li><li>计算直方图</li><li>计算HoG特征</li></ol><h2 id="3-1-计算梯度-compute-gradient"><a href="#3-1-计算梯度-compute-gradient" class="headerlink" title="3.1 计算梯度: compute_gradient():"></a>3.1 计算梯度: compute_gradient():</h2><p>参数：</p><ul><li>im: 灰度图片 (H, W)</li></ul><p>返回值：</p><ul><li>angles: 梯度角度 （H-2, W-2）</li><li>magnitudes: 梯度 （H-2, W-2）</li></ul><p>梯度的计算如下：</p><ul><li>给定一个像素和周围8个方向的像素，</li></ul><pre><code>P1 P2 P3P4 P5 P6P7 P8 P9arctan(dy/dx) = (P2 - p8)/(p4 - P6)  [可以使用np.arctan2 : 更稳定]，结果为[-180,180)如果想要得到[0, 180],需要简单地增加180到给负的角度梯度： sqrt((P4 - P6)^2 + (p2- P8)^ 2)</code></pre><pre><code class="python">def compute_gradient(im):    H, W = im.shape    angles = np.zeros((H-2, W-2))    magnitudes = np.zeros((H-2, W-2))       # 建立两个返回值矩阵    for i in range(1, H-1):        for j in range(1, W-1):     # 最外圈的点不计算            top = im[i-1, j]            down = im[i+1, j]            left = im[i, j-1]            right = im[i, j+1]      # 上下左右            angle = np.arctan2(top - down, left - right) * (180 / math.pi)      # 转化为度            magn = np.sqrt((top-down)**2 + (left - right)**2)            if(angle &lt; 0):      # 加180                angle += 180            angles[i-1, j-1] = angle            magnitudes[i-1, j-1] = magn    return angles, magnitudes</code></pre><h2 id="3-2-生成直方图：-generate-histogram"><a href="#3-2-生成直方图：-generate-histogram" class="headerlink" title="3.2 生成直方图： generate_histogram()"></a>3.2 生成直方图： generate_histogram()</h2><p>通过给定的角度矩阵和梯度矩阵，生成角度直方图</p><p>参数：</p><ul><li>angles: （M, N）</li><li>magnitudes:(M,N)</li><li>nbins: 直方图区间数</li></ul><p>返回值：</p><ul><li>histogram： 多维数组(nbins,),包含梯度角的分布</li></ul><p>实现：</p><ol><li>每个直方图应该被划分为0到180度，nbins决定区间数</li><li>迭代，将每个对应的梯度角度放到对应的直方图区间中，为了合理分配到两个相近的区间，使用如下公式：</li></ol><pre><code># center_angle 为 区间的中心，比如 20度的区间，第一个和第二个区间的中心为10,30    histogram[bin1] += magnitude * |angle - center_angle2 | / (180 / nbins)            histogram[bin2] += magnitude * |angle - center_angle1 | / (180 / nbins)</code></pre><p>认为第1个区间和最后一个区间相邻；</p><pre><code class="python">def generate_histogram(angles, magnitudes, nbins = 9):    histogram = np.zeros(nbins)    bin_size = 180 / nbins    center_angles = np.zeros_like(histogram)    for i in range(nbins):        center_angles[i] = (0.5 + i) * bin_size     # 计算每个区间中心    M, N = angles.shape    for m in range(M):        for n in range(N):            angle = angles[m, n]            magn = magnitudes[m, n]            abs_diff = np.abs(center_angles - angle)            # 当 angle 趋于0度            if (180 - center_angles[-1] + angle) &lt; abs_diff[-1]:        # 更新下最后区间的大小                abs_diff[-1] = 180 - center_angles[-1] + angle            # angle趋于180度            if(180 + center_angles[0] - angle) &lt; abs_diff[0]:                abs_diff[0] = 180 - angle + center_angles[0]            # 统计直方图            bin1, bin2 = np.argsort(abs_diff)[0:2]      # 取最近的两个            histogram[bin1] += magn * abs_diff[bin2] / (180.0 / nbins)            histogram[bin2] += magn * abs_diff[bin1] / (180.0 / nbins)    return histogram</code></pre><h2 id="3-3-计算HoG特征：-compute-hog-features"><a href="#3-3-计算HoG特征：-compute-hog-features" class="headerlink" title="3.3 计算HoG特征： compute_hog_features()"></a>3.3 计算HoG特征： compute_hog_features()</h2><p>参数：</p><ul><li>im： 图片矩阵</li><li>pixels_in_cell: 每个单元格的大小</li><li>cenlls_in_block:    每个block中的cell数量</li><li>nbins: histogram bins</li></ul><p>返回值：</p><ul><li>features: hog 特征（H_blocks, W_blocks, cells_in_block * cells_in_block * nbins）</li></ul><p>实现：</p><ol><li>计算每个图片的梯度和角度</li><li>定义一个cell和block</li><li>定义一个滑动窗口，大小为一个block的大小，滑动步长为block的一半，每个block中的cell存储一个直方图中的梯度，<br>每个block 特征被表示为(cells_in_block， cells_in_block, nbins),也可表示为（ cells_in_block * cells_in_block * nbins ）<br>,确保归一化</li><li>返回这些所有网格的HoG特征</li></ol><pre><code class="python">def compute_hog_features(im, pixels_in_cell, cells_in_block, nbins):    # 第一步： 获得角度和梯度    angles, magnitudes = compute_gradient(im)    # 第二步： 划分block 和cell    cell_size = pixels_in_cell    block_size = pixels_in_cell * cells_in_block    # 第三步：计算滑动窗口    H, W = angles.shape    stride = int(block_size / 2)    H_blocks = int((H - block_size) / stride) + 1    W_blocks = int((W - block_size) / stride) + 1    # 第四步： 计算每个cell的 histogram    hog_fe = np.zeros((H_blocks, W_blocks, cells_in_block * cells_in_block * nbins))    for h in range(H_blocks):        for w in range(W_blocks):            block_angles = angles[h*stride: h * stride + block_size,                           w * stride: w*stride + block_size]      # 一个block的角度            block_magn = magnitudes[h*stride: h*stride+block_size,                            w*stride: w*stride+block_size]         # 梯度            # 将一个block中的每个cell表示为一个方向直方图            block_hog_fe = np.zeros((cells_in_block, cells_in_block, nbins))            for i in range(cells_in_block):                for j in range(cells_in_block):                        cell_angles = block_angles[i*pixels_in_cell : (i+1)*pixels_in_cell,                                        j*pixels_in_cell : (j+1)*pixels_in_cell]                        cell_magns = block_magn[i*pixels_in_cell : (i+1) * pixels_in_cell,                                        j*pixels_in_cell : (j+1) * pixels_in_cell]                        cell_hist = generate_histogram(cell_angles, cell_magns, nbins)                        block_hog_fe[i, j, :] = cell_hist            # 归一化            block_hog_fe = np.reshape(block_hog_fe, -1)            block_hog_fe /= np.linalg.norm(block_hog_fe)            hog_fe[h, w, :] = block_hog_fe    return hog_fe</code></pre><h2 id="3-4-结果"><a href="#3-4-结果" class="headerlink" title="3.4 结果"></a>3.4 结果</h2><p><img src="https://github.com/jingxa/cs231a_my/raw/master/images/ps3/hog.png" alt="hog"></p><hr>]]></content:encoded>
      
      <comments>https://jingxa.github.io/2018/10/25/CS231A-Homework-3-3/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
